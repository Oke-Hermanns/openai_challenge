{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd06b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "# Calculate distance between two points\n",
    "def euclidean_distance(p1, p2):\n",
    "    return math.dist(p1, p2)\n",
    "\n",
    "# Eye Aspect Ratio (basic version)\n",
    "def is_eye_open(eye_landmarks):\n",
    "    # Upper and lower lid midpoints\n",
    "    vertical = euclidean_distance(eye_landmarks[1], eye_landmarks[5])\n",
    "    horizontal = euclidean_distance(eye_landmarks[0], eye_landmarks[3])\n",
    "    ratio = vertical / horizontal\n",
    "    return ratio > 0.25  # Threshold (tweak based on tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5866201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745617640.714099   40808 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1745617640.716305   40889 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1745617640.719894   40870 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745617640.739604   40870 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False,\n",
    "                                  max_num_faces=1,\n",
    "                                  refine_landmarks=True,\n",
    "                                  min_detection_confidence=0.5,\n",
    "                                  min_tracking_confidence=0.5)\n",
    "\n",
    "# Eye landmark indices from MediaPipe (right and left)\n",
    "RIGHT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "LEFT_EYE  = [362, 385, 387, 263, 373, 380]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1ace71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1745617644.051016   40873 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEyes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meye_status\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m),\n\u001b[1;32m     26\u001b[0m                         cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m eye_status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     28\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEye Detection\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     32\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Flip for natural webcam feel\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            h, w, _ = frame.shape\n",
    "            right_eye = [(int(face_landmarks.landmark[i].x * w),\n",
    "                          int(face_landmarks.landmark[i].y * h)) for i in RIGHT_EYE]\n",
    "            left_eye = [(int(face_landmarks.landmark[i].x * w),\n",
    "                         int(face_landmarks.landmark[i].y * h)) for i in LEFT_EYE]\n",
    "\n",
    "            right_open = is_eye_open(right_eye)\n",
    "            left_open = is_eye_open(left_eye)\n",
    "\n",
    "            eye_status = \"Open\" if right_open and left_open else \"Closed\"\n",
    "            cv2.putText(frame, f\"Eyes: {eye_status}\", (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0) if eye_status == \"Open\" else (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Eye Detection\", frame)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
